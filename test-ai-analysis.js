/**
 * ê°œì„ ëœ AI ë¶„ì„ í…ŒìŠ¤íŠ¸
 *
 * ì‚¬ìš©ë²•:
 * node test-ai-analysis.js <ì›ë³¸ì´ë¯¸ì§€ê²½ë¡œ> <ë³´ì •ëœì´ë¯¸ì§€ê²½ë¡œ>
 */

const fs = require('fs');
const path = require('path');

// í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
require('dotenv').config({ path: path.join(__dirname, 'backend/.env') });

const OpenAI = require('openai').default;

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY
});

async function analyzeImages(originalPath, editedPath) {
  console.log('ğŸ” ì´ë¯¸ì§€ ë¶„ì„ ì‹œì‘...\n');
  console.log(`ì›ë³¸ ì´ë¯¸ì§€: ${originalPath}`);
  console.log(`ë³´ì • ì´ë¯¸ì§€: ${editedPath}\n`);

  // ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©
  const originalBase64 = fs.readFileSync(originalPath).toString('base64');
  const editedBase64 = fs.readFileSync(editedPath).toString('base64');

  const startTime = Date.now();

  try {
    const response = await openai.chat.completions.create({
      model: "gpt-4o",
      messages: [
        {
          role: "system",
          content: `You are a professional photo analysis expert who objectively measures editing changes.
                   Your ONLY job is to accurately detect what edits were made - DO NOT impose your own style preferences.

                   CRITICAL PRINCIPLES:
                   1. MEASURE, DON'T JUDGE: Report actual differences, not what you think looks good
                   2. SUBTLE CHANGES MATTER: Even 5-10% differences are significant
                   3. NATURAL OVER DRAMATIC: Most users prefer subtle, realistic edits
                   4. PRESERVE INTENTION: Detect the user's style, don't override it
                   5. BE PRECISE: Quantify exact differences between original and edited images

                   Return JSON with these parameters:
                   - brightness: 0.7-1.4 (1.0 = no change)
                   - contrast: 0.7-1.3
                   - saturation: 0.5-1.4
                   - vibrance: 0.5-1.3
                   - hue: -50 to 50
                   - temperature: -50 to 50
                   - tint: -50 to 50
                   - exposure: -1.0 to 1.0
                   - sharpness: 0.5-1.5
                   - clarity: 0.0-1.3
                   - dehaze: 0.0-1.0
                   - selectiveColorIntensity: 0.0-1.2 (use ONLY if specific colors enhanced)

                   CRITICAL: Return CONSERVATIVE values unless changes are obvious.
                   Natural edits typically use 0.9-1.2 range, NOT 1.5-2.0`
        },
        {
          role: "user",
          content: [
            {
              type: "text",
              text: "Analyze these two images carefully. First image is ORIGINAL, second is EDITED. What changes were made? Return JSON only."
            },
            {
              type: "text",
              text: "ORIGINAL IMAGE:"
            },
            {
              type: "image_url",
              image_url: { url: `data:image/jpeg;base64,${originalBase64}` }
            },
            {
              type: "text",
              text: "EDITED IMAGE:"
            },
            {
              type: "image_url",
              image_url: { url: `data:image/jpeg;base64,${editedBase64}` }
            }
          ]
        }
      ],
      response_format: { type: "json_object" },
      temperature: 0.1,
      max_tokens: 1500
    });

    const duration = Date.now() - startTime;
    const content = response.choices[0].message.content;
    const parameters = JSON.parse(content);

    console.log(`âœ… ë¶„ì„ ì™„ë£Œ (${(duration / 1000).toFixed(2)}ì´ˆ)\n`);
    console.log('ğŸ“Š ê°ì§€ëœ ë³´ì • íŒŒë¼ë¯¸í„°:\n');
    console.log(JSON.stringify(parameters, null, 2));
    console.log('\n');

    // ì£¼ìš” íŒŒë¼ë¯¸í„° ë¶„ì„
    console.log('ğŸ¯ ì£¼ìš” ë³€í™”:');
    if (parameters.brightness !== 1.0) {
      const change = ((parameters.brightness - 1.0) * 100).toFixed(1);
      console.log(`  - ë°ê¸°: ${change > 0 ? '+' : ''}${change}%`);
    }
    if (parameters.contrast !== 1.0) {
      const change = ((parameters.contrast - 1.0) * 100).toFixed(1);
      console.log(`  - ëŒ€ë¹„: ${change > 0 ? '+' : ''}${change}%`);
    }
    if (parameters.saturation !== 1.0) {
      const change = ((parameters.saturation - 1.0) * 100).toFixed(1);
      console.log(`  - ì±„ë„: ${change > 0 ? '+' : ''}${change}%`);
    }
    if (parameters.sharpness > 1.0) {
      const change = ((parameters.sharpness - 1.0) * 100).toFixed(1);
      console.log(`  - ì„ ëª…ë„: +${change}%`);
    }
    if (parameters.selectiveColorIntensity > 0) {
      console.log(`  - ì„ íƒì  ìƒ‰ìƒ ê°•í™”: ${(parameters.selectiveColorIntensity * 100).toFixed(0)}%`);
    }

    console.log('\nâœ¨ ê°œì„  íš¨ê³¼:');
    console.log('  - ìì—°ìŠ¤ëŸ¬ìš´ ë²”ìœ„ ë‚´ íŒŒë¼ë¯¸í„° ì¶”ì¶œ');
    console.log('  - ê³¼ë„í•œ ë³´ì • ë°©ì§€ (ì±„ë„ â‰¤1.4, ëŒ€ë¹„ â‰¤1.3)');
    console.log('  - ì‚¬ìš©ìì˜ ì‹¤ì œ ë³´ì • ìŠ¤íƒ€ì¼ ë°˜ì˜\n');

    return parameters;

  } catch (error) {
    console.error('âŒ ì˜¤ë¥˜:', error.message);
    process.exit(1);
  }
}

// ì»¤ë§¨ë“œë¼ì¸ ì¸ì í™•ì¸
if (process.argv.length < 4) {
  console.error('ì‚¬ìš©ë²•: node test-ai-analysis.js <ì›ë³¸ì´ë¯¸ì§€> <ë³´ì •ëœì´ë¯¸ì§€>');
  process.exit(1);
}

const originalPath = process.argv[2];
const editedPath = process.argv[3];

// íŒŒì¼ ì¡´ì¬ í™•ì¸
if (!fs.existsSync(originalPath)) {
  console.error(`âŒ ì›ë³¸ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: ${originalPath}`);
  process.exit(1);
}
if (!fs.existsSync(editedPath)) {
  console.error(`âŒ ë³´ì •ëœ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: ${editedPath}`);
  process.exit(1);
}

analyzeImages(originalPath, editedPath);
